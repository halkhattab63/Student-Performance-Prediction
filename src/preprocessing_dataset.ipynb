{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4ee3a4",
   "metadata": {},
   "source": [
    "\n",
    "# Data Preprocessing Pipeline\n",
    "\n",
    "This notebook performs the following preprocessing steps on the dataset:\n",
    "1. One-hot encoding of categorical variables\n",
    "2. Classification of final grades (G3) into Low, Medium, and High\n",
    "3. Outlier removal using IQR method\n",
    "4. Min-Max Scaling of numeric features\n",
    "5. Saving the final cleaned dataset\n",
    "\n",
    "Make sure `final_combined_dataset.csv` is present in the same directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7bed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def classify_grade(g):\n",
    "    if g <= 9:\n",
    "        return \"Low\"\n",
    "    elif g <= 14:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "def remove_outliers_iqr(df, numeric_cols):\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "def full_preprocessing_pipeline(input_csv, output_csv):\n",
    "    # Step 1: Load dataset\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Step 2: One-hot encode categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=False)\n",
    "\n",
    "    # Step 3: Classify G3\n",
    "    if 'G3' in df_encoded.columns:\n",
    "        df_encoded['G3_Class'] = df_encoded['G3'].apply(classify_grade)\n",
    "\n",
    "    # Step 4: Remove outliers\n",
    "    numeric_cols = df_encoded.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if 'G3' in numeric_cols:\n",
    "        numeric_cols.remove('G3')\n",
    "    df_clean = remove_outliers_iqr(df_encoded, numeric_cols)\n",
    "\n",
    "    # Step 5: Scale features\n",
    "    X = df_clean.drop(columns=['G3', 'G3_Class'], errors='ignore')\n",
    "    y = df_clean['G3_Class']\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    df_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "    # Step 6: Merge features with target\n",
    "    df_scaled['G3_Class'] = y.values\n",
    "\n",
    "    # Step 7: Save to CSV\n",
    "    df_scaled.to_csv(output_csv, index=False)\n",
    "    print(f\"âœ… Dataset processed and saved to: {output_csv}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    full_preprocessing_pipeline(\n",
    "        input_csv=\"final_combined_dataset.csv\",\n",
    "        output_csv=\"full_processed_dataset.csv\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
